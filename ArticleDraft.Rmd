---
title: "Exploring Real Data: A look at AirBnB"
author: "Amanda Francis and Eric Sullivan"
date: " "
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2) # graphics
library(dplyr) # data wrangling
library(cowplot) #plot grids
library(knitr) # fancy tables
library(GGally) # scatterplot matrices
library(tree) # regression trees
library(rpart) #classification trees

seattle<-read.csv('Airbnb_Seattle.csv')
currency_to_numeric <- function(x){
  # Convert currencies to numeric i.e. strip dollar signs and commas
  x <- gsub('\\$','', as.character(x))
  x <- gsub('\\,','', as.character(x))
  x <- as.numeric(x)
  return(x)
}
seattle<-seattle %>% mutate(price = currency_to_numeric(price))
```


## Airbnb
We have all likely experienced the traveler’s dilemma: I want to travel cheaply so that my trip can last longer, but the cost of lodging is prohibitively high.  In 2008 the San Francisco based company Airbnb changed the nature of finding lodging and provided an alternative to traditional hotels by creating “ … a trusted community marketplace for people to list, discover, and book unique accommodations around the world”.  In their words:  “whether an apartment for a night, a castle for a week, or a villa for a month, Airbnb connects people to unique travel experiences, at any price point, in more than 65,000 cities and 191 countries” (www.airbnb.com). 

As Airbnb has grown in popularity a wealth of data has been accumulated about many aspects of the Airbnb experience. One particular independent website, insideairbnb.com, has developed “ … a set of tools and data that allows you to explore how Airbnb is really being used in cities around the world.”  Insideairbnb has gathered public data from Airbnb sites around the world and as mathematicians and statisticians this provides us with a treasure trove of questions to explore!  They have data on cities like Paris, Venice, Amsterdam, Boston, Chicago, Seattle, and many more.  Their data sets include factors such as average reviews, locations, cleaning costs, rent, and much more.  

What follows are a collection of explorations that you can try out along with us.  After each exploration we’ll give some of our own thoughts, discussion, and visualization.  We encourage the reader to head over to insideairbnb.com, find some interesting data, and start exploring.

### Exploration #1: 
Go to insideairbnb.com now and find a data set for the city of your choice.  Spend a few minutes exploring the data set and propose several questions.  When you press “Get the Data” on insideairbnb.com and find your city you will see a link “see data visually here”.  Spend some time exploring their visual aids.

![](SeattlePic.png)

We are located somewhat near Seattle, so for the purposes of discussion we’ll use the Seattle data.  You are welcome to use whichever data set you find most interesting.  The graphical visualization tool allows you to see several descriptive statistics for your chosen city, animate through the frequency and location of reviews, see top rated hosts, and much more.
   
## Initial Exploratory Data Analysis
<!--As a way to motivate statistical thinking and exploration on these large Airbnb data sets--> Let’s explore a some questions related to your particular city (These explorations are meant to increase in difficulty as you work through them).  



### Exploration #2: 
You’re trying to budget your travel money.  In what range of daily prices would you expect the average daily price for a private room at an Airbnb in a particular neighborhood to land?  <!-- **This data isn't normally distributed, so we need to be careful giving confidence intervals for single instances...** -->

**Discussion:** There is a beautiful beach on the Puget Sound in the Alki neighborhood of Seattle.  Let's filter the data to explore the prices from the Alki beach area.  We'll start with some basic descriptive statistics: the average rental price there is $170 but the standard deviation is $97!  The question in this exploration is really asking for a range of prices, and based on the rather large standard deviation, the estimation range will have a rather large range as well.  If this data were normally distributed we would expect *most* of the rentals (~68% of them) to be withing one standard deviation of the mean: between $73 and $267. <!--We expect the price for a rental in the Alkai neighborhood to be somewhere between $140 and $201.  In fact, a 95% confidence interval for the average price in this neighborhood is between $8 and $355!-->  The large variance in the prices leads us to believe that there is more going on here.  Let's create a data visualization to investigate further: 
```{r, echo = F,fig.height = 2,fig.width = 5}
seattle1<-seattle %>% filter(host_neighbourhood == 'Alki')
m = mean(seattle1$price)
s = sd(seattle1$price)
df<-data.frame(id = c(1,1,1,1),x = c(.5,.5,1.5,1.5), y = c(m+s, m-s, m-s, m+s))
ggplot(seattle1, aes(x = 'Alki', y = price)) + geom_violin(fill = 'cyan')+
  geom_segment(x = 0, xend = 1.5, y = m, yend = m, color = 'salmon')+
  geom_segment(aes(x = .5, xend = 1.5, y = m-s, yend = m -s ), lineend = "butt", color = 'Lightpink')+
  geom_segment(aes(x = .5, xend = 1.5, y = m+s, yend = m +s ), lineend = "butt", color = 'Lightpink') + 
  geom_boxplot(width = .4, fill = 'Lightblue')+coord_flip() + xlab('Neighborhood') + 
  ggtitle('Distribution of Prices in the Alki Neighborhood')


#ggplot(seattle1, aes(x = room_type, y = price)) + geom_violin(aes(fill = room_type)) +
#  geom_boxplot(width = .25,aes(fill = room_type ))+coord_flip()


```

<!--The most likely candidate is the type of rental (room vs. apartment vs. house).  Let’s say that we’re a bit more picky and only want a room (we’re on a budget after all).  Now after a bit more sorting and filtering the average price is only $130 but the standard deviation is even larger: $113!  Wow!  A 95% confidence interval gives a range of $45 to $220!  Well, at least we expect to find a few cheap rooms for rent.-->

The plot above is called a violin plot.  The curved shape tells us where 'clusters' of the data are located, while the boxplot tells us where the median and quartiles are located.  We observe that this data does *not* appear to be normally distributed. In fact, a relatively low concentration of the rentals in the Alki neighborhood are near the median price; many are between $40 and $80 away from the 'center', in other words, this is a bimodal distribution of data.  We could investigate the types of rentals in this data, or perhaps, their distance from the coastline to figure out what is creating this interesting shape. In addition, if we want to use prices in this neighborhood as part of some further analysis, we might consider performing some kind of variable transformation.  Since the prices here are all greater than zero, bimodal, and fairly "right skewed"", we notice that the distribution is not 'nearly normal' like we have come to expect!  A square root or log transformation might prove useful for further analysis.

### Exploration #3:  
Do you wonder if hosts with cleaner rentals charge more?  How about a more specific question:  is there a statistical difference in daily price between the rentals that are rated most cleanly versus the rentals that are rated least cleanly?

**Discussion:** 
The first order of business in this exploration is to decide what *most cleanly* and *least cleanly* mean to us.  The cleanliness rating scale goes from 0 to 10, but we shouldn't assume that cleanliness ratings are evenly distributed among these numbers, or that the numbers 0-10 represent a linear progression of cleanliness.  In fact, many travelers might feel guilty giving a low cleanliness rating, so we may expect the ratings to be artificially inflated. Having learned from our last exploration, this time let's look at a visualization of the data first.  How about a scatterplot of cleanliness rating versus price?  

```{r, echo = F, fig.height=2, fig.width = 5 }
seattle1<- seattle %>% 
  #filter(room_type == 'Private room') %>%
  select(review_scores_cleanliness, price)
seattle1<- seattle1 %>% filter(review_scores_cleanliness != 'N/A')

ggplot(seattle1, aes(x = review_scores_cleanliness, y = price)) + geom_point()+
  ggtitle('Scatterplot') + xlab('Cleanliness Score')
```

One problem with this graphic is that the dots we've plotted are likely hiding information from us! Some of the dots might represent only one observation, while some may have many rental observations which happen to have the same cleanliness review score and price as many others. 

One option is to add a ‘jitter’ to our graphic, so that we can see all of our points (or at least get a sense about where our clusters are. 


```{r, echo = F, fig.height=2.5 }
#p1<-ggplot(seattle1, aes(x = review_scores_cleanliness, y = price)) + geom_point()+
#  ggtitle('Scatterplot') + xlab('Cleanliness Score')
ggplot(seattle1, aes(x = review_scores_cleanliness, y = price)) +
  geom_jitter(shape = 1) + 
  geom_segment(y = 0, yend = 1000, x = 7.5, xend = 7.5 )+
  ggtitle('Jittered Scatterplot')+ xlab('Cleanliness Score')
#plot_grid(p1,p2,nrow=2)
```

Here we notice that the sample sizes are wildly different: 80 rentals with lower cleanliness ratings and 3,165 with higher ratings.  Perhaps people are just too nice in their ratings or perhaps the Airbnb properties in Seattle are clean! It *looks* like the rentals rated higher for cleanliness get better prices, perhaps with a few outliers. Our scatterplot dots are still so clustered that it makes it hard for us to see what's going on. Let's try one more data visualization.  In the last exploration we looked at a violin plot, and it seemed useful; this time let's look at a side-by-side violin plot. In this case, we've added a log-scale to the price variable, to make the shapes easier to see. 



```{r, echo = F, fig.height = 2.5}



seattle1 <- seattle1 %>% mutate(HiLo = ifelse(review_scores_cleanliness>=8, 'High', 'Low'))

#ggplot(seattle1, aes(x = HiLo, y = price, fill = HiLo))+
#  geom_violin()+geom_boxplot( width = .4)+coord_flip()+
#  theme(legend.position = "none")+
  #scale_y_log10() + 
#  xlab('Cleanliness Rating') + ylab('Price')+ggtitle('Regular Scale')

ggplot(seattle1, aes(x = HiLo, y = price, fill = HiLo))+
  geom_violin()+geom_boxplot( width = .4)+coord_flip()+
  theme(legend.position = "none")+
  scale_y_log10() + 
  xlab('Cleanliness Rating') + ylab('Price')+ggtitle('Price on a Log Scale')

#ggplot(seattle1, aes(fill = HiLo, x = price))+stat_density()+
#  scale_x_log10() + ylab('Cleanliness Rating') + xlab('Price')+ggtitle('Distribution #of Daily Prices for High and Low Cleanliness Ratings')

```

 We see that actually, the bulk of the rental prices for *both* High and Low ratings fall below \$250, but the high rentals have some 'outlier' observations with much higher prices.  On the whole, though, the average rental in either category doesn't appear to be much different. If we conduct a statistical $t$-test on two means, we come to roughly the same conclusion (with a p-value of about 0.26), so there doesn't appear to be strong evidence of a difference in price between the two groups.  <!--At least we know that if we stay at an Airbnb rental with a higher cleanliness rating we aren’t likely being charged more.  -->

```{r, eval = F, echo = F}
# Difference of means test:

summ<-seattle1 %>% group_by(HiLo) %>% 
  summarise(m = mean(price), s = sd(price), n = n())
summ
xbardiff = summ[[1,2]] - summ[[2,2]]
stderror = sqrt(summ[[1,3]]^2/summ[[1,4]] + summ[[2,3]]^2/summ[[2,4]])
tstat = xbardiff/stderror
2*pt(-tstat,9)
```



### Exploration #4:  
I want to be safe and allow myself an out in case my travel plans fall through, but I still want to have several Airbnb rentals to choose from.  Is there a difference between the proportion of rentals in one neighborhood that have a strict cancellation policy as compared to the rentals in another neighborhood?

**Discussion:** Let’s say that we want to stay on the waterfront in Seattle so we’ll compare Alki beach and Belltown; both of which are on the water. 

```{r, echo = F, fig.height=2.5}
seattle1<-seattle %>% select(cancellation_policy, host_neighbourhood)

seattle1<- seattle1 %>% filter( (host_neighbourhood == 'Alki' | 
                                      host_neighbourhood == 'Belltown'))

ggplot(seattle1, aes(x = host_neighbourhood, fill = cancellation_policy)) + 
  geom_bar(position = 'fill') + coord_flip() + ylab('Proportion')+ xlab('Neighborhood')+
  ggtitle('Cancellation Policy in Two Neighborhoods')
```

The visualization above shows us the distribution of cancellation policies in the two neighborhoods, and a statistical test on the difference of the  proportions of `strict policies` in each neighborhood gives us a p-value around .0004, and we  conclude that there is evidence to suggest that rentals in Belltown have a much stricter cancellation policy than those in Alki.  The safe bet seems to be Alki, but if we want to spend our social time in downtown we now need to consider the transportation costs.

```{r, include = F}
# Difference of proportions test:
mytable1<-seattle1 %>% filter(cancellation_policy=='strict')%>%
  group_by(host_neighbourhood) %>% tally()
mytable2<-seattle1 %>% group_by(host_neighbourhood) %>% tally()
mytable1
mytable2
p1hat= mytable1[[1,2]]/mytable2[[1,2]]
p2hat= mytable1[[2,2]]/mytable2[[2,2]]
phatdiff = p1hat - p2hat
ppooled = (mytable1[[1,2]]+mytable1[[2,2]])/(mytable2[[1,2]]+mytable2[[2,2]])
stderror = sqrt(ppooled*(1-ppooled)*(1/mytable2[[1,2]]+1/mytable2[[2,2]]))
tstat = phatdiff/stderror
2*pnorm(tstat)

seattle1<-seattle %>% select(cancellation_policy, neighbourhood_cleansed)

seattle1<- seattle1 %>% filter( (neighbourhood_cleansed == 'Alki' | 
                                      neighbourhood_cleansed == 'Belltown'))

ggplot(seattle1, aes(x = neighbourhood_cleansed, fill = cancellation_policy)) + 
  geom_bar(position = 'fill') + coord_flip() + ylab('Proportion')+ xlab('Neighborhood')+
  ggtitle('Cancellation Policy in Two Neighborhoods')

mytable1<-seattle1 %>% filter(cancellation_policy=='strict')%>%
  group_by(neighbourhood_cleansed) %>% tally()
mytable2<-seattle1 %>% group_by(neighbourhood_cleansed) %>% tally()
mytable1
mytable2
p1hat= mytable1[[1,2]]/mytable2[[1,2]]
p2hat= mytable1[[2,2]]/mytable2[[2,2]]
phatdiff = p1hat - p2hat
ppooled = (mytable1[[1,2]]+mytable1[[2,2]])/(mytable2[[1,2]]+mytable2[[2,2]])
stderror = sqrt(ppooled*(1-ppooled)*(1/mytable2[[1,2]]+1/mytable2[[2,2]]))
tstat = phatdiff/stderror
pvalue = 2*pnorm(tstat)

#p-value = 9.214435e-05

```



### Exploration #5:
Now I'm considering inviting some friends on my trip, but first I want to know: For each additional bed,  how much more should I expect a rental to cost? 


**Discussion:**
Let's start with a visualization of our data points in a (jittered) scatterplot and a contour plot showing which combinations of number of beds and rental price occur most frequently.

```{r,echo = F, fig.height = 2.5,message = F, warnings = FALSE}
seattle1<-seattle %>% select(price, beds)
seattle1<-na.omit(seattle1)
#ggpairs(airbnb6)

seattle1<-seattle1 %>%filter(beds<=14)

p1<-ggplot(seattle1, aes(x = beds, y = price)) + geom_jitter(shape = 1) + xlim(0,11)+
  #ggtitle('Price versus Number of Beds')#+ 
  geom_smooth(method = 'lm',se = F)

#p1
#ggplot(seattle1, aes(x = beds, y = price)) + 
#  stat_density2d(aes(fill = ..level..), geom="polygon")+
#  xlim(0.5,11)+ylim(0,1000)

p2<-ggplot(seattle1, aes(x = beds, y = price)) + 
  stat_density2d(na.rm=TRUE) + xlim(0.5,3.5) +ylim(0,250)
  #geom_smooth(method = 'lm')+
  #ggtitle('2D Density Contours')

plot_grid(p1, p2)
m1<-with(lm(price~beds), data = seattle1)
s<-summary(m1)
#kable(s$coefficients)

```

A simple linear regression tells us that the best-fit line for our data is approximately $Price = \$46 + 47\cdot beds$, 
so, I should expect to pay about \$93 for a rental with one bed and \$47 more per additional bed. As an additional exploration, you might try find a 95% confidence interval for the true slope (marginal price) of this regression line.  What about a 95% confidence interval for the average price of rentals with 3 beds?  What about a predicted interval for the *actual* price of a rental with 3 beds?  (How are these questions different from each other?)


<!--Do hosts that get more reviews have rentals priced differently than those with fewer reviews?  

*Discussion:* To explore this question we first need to sort the data and clean out any observations that contain missing information.  This first step is called data tidying or, more loosely, data wrangling and is an important step in the data analysis process.   Next, we may want to create a data visualization to help us sense what is going on here. 

```{r, include = F}
seattle1<-seattle %>% select(number_of_reviews, price) 
ggplot(seattle1, aes(x = number_of_reviews, y = price )) + geom_point() + 
  geom_smooth(method = 'lm')
m<-lm(price~number_of_reviews, data = seattle1)
#pander(summary(m))

ggplot(seattle1, aes(x = number_of_reviews, y = rstandard(m) )) + geom_point() + 
  geom_smooth(method = 'lm')
#pander(summary(m))

```

The question in Exploration #2 really asks to compare the mean daily prices of rentals between two distinct subgroups.  This just begs for a two-sample T test!  In the Seattle data set we find a p-value on the order of p=10-10 and hence would conclude that the two types of properties have statistically different daily prices.  But how different are they?  The actual difference between the average prices is only \$18.  Does the fact that the prices are statistically different mean that they are practically significant.  Doing a 95% confidence interval on the difference tells us that the average price for rooms with fewer than 6 reviews is likely \$13 to \$25 more expensive than the rentals with 6 or more reviews!  There might be all sorts of social reasons for this, but it looks like if you want to save the extra \$20 then you should probably rent an Airbnb that has 6 or more reviews. : -->




## Moving Beyond the Basics 
In this section we pose more questions and leave the investigations open to you. If you would like to see how we answered these questions wth the Seattle data, you can visit our workfile at mathquest.carroll.edu/AirbnbExplorations/.  Several of these exercises suggest more advanced techniques, such as multiple regression, logistic regression, or machine learning techniques to answer.

###Exploration #6: 
What variables in this data set do you think would be the most useful in predicting the price of a particular rental?  Try `accommodates`, `beds`, `bathrooms`, `guests_included`, `review_scores_rating`, and various neighborhoods, and see if you can build a model (maybe a multiple regression, regression tree, or artificial neural network) that is *good* at predicting prices. A good idea would be to split your data into a training and test sets so that you can test your predictions on data that your model has not seen.  Which variables turn out to be the most important?  The least inportant?  Does this surprise you?  Are there any variables that amount to just 'noise' in this analysis?  How reliable do you think your model is?  Do you think this same model would work in other regions of the world?  Why or why not? Do you think it would be necessary to pre-process that data in any way? <!--For example, do you think that it would be necessary to do a principal component analysis on your data first in order to reduce the dimension of the data set?-->  Do you think that the variables should be transformed in any way? Do you think any additional features should be included in your data (e.g. the square of a feature, the product of two features, etc)?


<!--… multiple regression … I think we should try to predict the price of a rental unit based on the variables accommodates + beds + bathrooms +guests_included+ review_scores_rating+QA(dummy variable for Queen Anne nbd) + BTown(dummy variable for Belltown nbd)+CH(dummy variable for Capitol Hill nbd).  We try to decide which variables should count for most.  I would like to include a scatterplot matrix here. -->

```{r, echo = F, eval = F}
seattle1<-seattle %>% select(price, accommodates, beds, bathrooms,
                            guests_included,review_scores_rating, neighbourhood_cleansed)

#What are the most popular neighbourhoods? 
seattle1 %>% group_by(neighbourhood_cleansed) %>% tally() %>% arrange(desc(n))

nbd_list<-c('Broadway', 'Wallingford', 'Belltown')
seattle1<-seattle1 %>% filter(neighbourhood_cleansed %in% nbd_list)

#Let's look at how these variables relate to each other: 
ggpairs(seattle1, cardinality_threshold = 90)

#It looks like price is correlated with accomodates, beds, and baths ... but these are also correlated with each other! Does it seem to be related to neighbourhood? 

seattle1 %>% group_by(neighbourhood_cleansed) %>% summarise(mean = mean(price), median = median(price))
#Belltown seems to cost more than the other two.  Let's create a dummy variable for Belltown. 

seattle1<- seattle1 %>% mutate(BT=ifelse(neighbourhood_cleansed=='Belltown',1,0))

#================== Use Multiple Regression =====================

m1<-lm(price~ accommodates+beds+bathrooms +guests_included+review_scores_rating+BT, data = seattle1 )
summary(m1)

#At first glance it appears that we can explain about 43% of the variation in price using these variables, and the ones that seem to contribute the most are 'accomodates', 'bathrooms, 'guests_included', and 'BT' (perhaps, in that order).  But... does it seem weird to you that 'beds' is not in this list? Can you explain why it's not? There are many ways to decide which variables to include (like stepwise regression, or contextual knowledge of the problem).  Let's naively just take the ones I mentioned above: 

seattle2<-seattle1 %>% select(price, accommodates, bathrooms, guests_included, BT)
seattle2<-na.omit(seattle2)
m2<-lm(price~ accommodates+bathrooms +guests_included+BT, data = seattle2 )
summary(m2)
stres<-rstandard(m2)
#Interestingly, we can now explain something like 47% of the variation in price, suggesting some of the variables we dropped were maybe acting like red herrings!  If we choose to accept this model (which, by the way, we shouldn't -- at least not until we assess its validity!), a practical description of the model would be: 

#An (empty) rental costs $0. 
# - For every person the rental accomodates, add $25.65 to the price
# - For every bathroom in the rental, add $35.69 to the price
# - For each guest included, add $7.27 o the rental price
# - If the rental is in BellTown, add $19 to the price

#Assess validity of model: Do the residuals appear to be normally distributed? 
p1<-ggplot(seattle2, aes(x = accommodates, y = rstandard(m2))) + geom_point(shape = 1)
p2<-ggplot(seattle2, aes(x = bathrooms, y = rstandard(m2))) + geom_point(shape = 1)
p3<-ggplot(seattle2, aes(x = guests_included, y = rstandard(m2))) + geom_point(shape = 1)
p4<-ggplot(seattle2, aes(x = lm.influence(m2)$hat, y = rstandard(m2))) + 
  geom_point(shape = 1) + 
  geom_vline(xintercept = 2*(5)/length(stres), color = 'cyan')+ 
  geom_hline(yintercept = -4, color = 'red')+ 
  geom_hline(yintercept = 4, color = 'red')
plot_grid(p1,p2,p3,p4)
ggplot(seattle2, aes(x = fitted(m2), y = price)) + geom_point(shape = 1)

#While there is no recognizable nonlinear shape in these residual plots, we do have a number of 'outlier + leverage' points that could be skewing things for us.  Also, the variation of residuals appears to be growing as accomodates/bathroom get larger. So, this model has some problems. 

#==================Use A Regression Tree=====================

#The following code produces a regression tree for this problem:
t<-tree(price~ accommodates+beds+bathrooms +guests_included+review_scores_rating+BT, data = seattle1 )
t
plot(t)
text(t) # *********** this line errors **************

#It appears that the most important variable in the data is 'accomodates'.  
#If you just want to split the data into two groups, you should look to see if the renatl accomodates 8 or more people.  If so, the average price would be $390, if not the average price would be $125.  
#For the rentals which accomodate less than 8 people, the next break occurs depending on if he rental accomodates four or more people (average price $163.10) or not (average price $102.20). #The next break occurs in the rentals that accommodate more than 8 people: rentals in Belltown (average price $539) or not (average price $342.70).

#We can keep following the 'breaks' in this regression tree until a good 'cut-off point'.  Finding the right cut-off point is an interesting problem which you should learn more about.  
# Further Questions: 
#1 - Can you interpret the meaning behind all of the breaks? 
#2 - Does the regression tree change your mind about which variables (in which cases) are practically significant? 
#3 - Which model do you think is better?

```


### Exploration #7: 
Can you use the data to predict whether a rental is an "Entire home" or a "Private room"" based on the other characteristics of that rental? 
What variables in this data set do you think would be the most useful to you?  Try using the same variables as in the last exploration (including price) to build a model? Which variables are the most important?  The least important?  Does this surprise you?  Are there any variables that amount to just 'noise' in this analysis?  How reliable do you think your model is?  **Do you think this same model would work in other regions of the world? Why or why not? Once you have a model working on your chosen city, try your model on a different city and see how it performs.**  It would also be wise in this case to split your data into a training set and a test set so that you can measure the performance of your model. 

<!--… logistic regression … I think we should try to model the probability that a rental is an ‘entire house’-type rental based on either the price or the number of beds (or the # of people the rental accommodates?).  Below is an example graphic.-->

```{r, eval = F, echo = F}
#================== Use Multiple Logistic Regression =====================

seattle1<-seattle %>% select(room_type, price, accommodates, beds, bathrooms,
                            guests_included,review_scores_rating, neighbourhood_cleansed)
seattle1<- seattle1 %>% filter(room_type != 'Shared room')
seattle1<- seattle1 %>% mutate(Home = ifelse(room_type == 'Private room', 0, 1))

#Which neighborhoods have more Private rentals? 
seattle1 %>% group_by(neighbourhood_cleansed) %>% summarize(p = mean(Private))%>%
  arrange(p)

#Suppose we only use price to predict whether a rental is a private room (instead of an entire house)


m1<-glm(Home~ price, family = binomial, data = seattle1 )
c<-coefficients(m1)

f<-function(x){1/(1 + exp(-c[[1]] -c[[2]]*x))}

seattlebinned<-seattle1 %>% mutate(pricebin = cut(price, breaks = 20*0:100, labels = 20*0.5:99.5))
seattleb<-seattlebinned %>% group_by(pricebin) %>% summarise(p = mean(Home))
ggplot(seattleb, aes(x = currency_to_numeric(pricebin), y = p)) + geom_point()+
  stat_function(fun = f, color = 'blue') + xlab('Price')+xlim(0,500)
#The graphic deomonstrates that an increase of price is linked to an increased likelihood that the rental is an entire home. 


summary(m1)
#The summary tells us that we estimate that the odds of a house being an entire home go up by .04 for every additional dollar in the price of the rental. 

#How well does this logistic regression do as a predictor? 
library(mclust)
seattle1<- seattle1 %>% mutate(Predict = ifelse(fitted(m1)>.5, 1, 0))
classError(seattle1$Home,seattle1$Predict )
#The classError function above tells us that our prediction gives us a 16% error rate. 

# Let's try adding more variables: 

seattle2<-na.omit(seattle1)
m2<-glm(Home~ accommodates+beds+bathrooms +guests_included+review_scores_rating + price, family = binomial, data = seattle2 )
summary(m2)


m3<-glm(Home~ accommodates+bathrooms +review_scores_rating + price, family = binomial, data = seattle2 )
summary(m3)


seattle2<- seattle2 %>% mutate(Predict = ifelse(fitted(m3)>.5, 1, 0))
classError(seattle2$Home,seattle2$Predict )
#New error rate: 13%.  Not that much better? 

#================== Use Classification Tree =====================

t<-rpart(Home~ accommodates+beds+bathrooms +guests_included+review_scores_rating + price, 
         data = seattle2 )
t
plot(t, compress = TRUE)
text(t, use.n = TRUE)

#Fix plot and add interpretation

```


### Exploration #8: 
Can you use the data to predict which neighborhood a rental is in based on other characteristics in the data?  Pick three or four neighborhoods which contain "many" rentals and keep only data from these neighborhoods.  Can you build a model (maybe hierarchical clustering, k-means, or something else) which can predict which neighborhood you're in, based on certain *important* variables? Which variables do you think you should use?  Do you think using `latitude` and/or `longitude` is like cheating?    How well does your model work?

```{r, eval = F, echo = F}

seattle1<-seattle %>% select(room_type, price, accommodates, beds, bathrooms,
                            guests_included ,review_scores_rating,
                            neighbourhood_cleansed,latitude, longitude)
#Which nbds should we pick
seattle1 %>% group_by(neighbourhood_cleansed) %>% tally() %>% arrange(desc(n))
#Howabout: 
nbd_list<-c('Broadway', 'Belltown', 'Wallingford', 'University District', 'Minor')
seattle1<-seattle1 %>% filter(neighbourhood_cleansed %in% nbd_list)
ggplot(seattle1, aes(x = longitude, y = latitude, color = neighbourhood_cleansed)) + 
  geom_point()

seattle1 %>% tbl_df()

clusters<-seattle1 %>%
  mutate(Home = ifelse(room_type == 'Entire home/apt',1,0)) %>%
  select(-neighbourhood_cleansed,-room_type)

clusters<-na.omit(clusters)
km<-kmeans(cbind(clusters[,1:8]),5)
clusters<-clusters %>% mutate(Predict = km$cluster)

ggplot(clusters, aes(x = longitude, y = latitude, color = as.factor(Predict))) + 
  geom_point()

#Still need to play around with variables.  Or, just give up and use latitude and longitude only...

```

##Conclusions
The Insideairbnb data set is robust enough that anyone with statistical training, no matter the sophistication, can ask meaningful and challenging questions.  In recent times the field of data science, along with the associated mathematical tools, has become a successful and popular way to analyze data sets of this type. If you want to learn more about exploring and using data for analysis and predictions there are starter courses on the web (e.g., Coursera and DataCamp) and many universities and colleges around the world are implementing Data Science programs.  Most importantly, as you may have found from the last three exercises, the level of mathematical sophistication associated with data analysis can be quite high, so if you are a student reading this article and you find the ideas interesting then we recommend taking courses in statistics, computer science and computational mathematics.

There are many data sets like Insiderairbnb available for free on the internet.  For example, the University of California, Irnive, hosts a collection of machine learning data sets that are at least as rich and interesting (archive.ics.uci.edu/ml/).  Other sites to look at when seeking data sets include data.gov, kaggle.com, quandl.com, gapminder.org, flowingdata.com, and many others.  The world of data and data analysis is growing in importance socially and mathematicians and statisticians are uniquely positioned with their training to approach these questions with proper skills and mindsets. 
